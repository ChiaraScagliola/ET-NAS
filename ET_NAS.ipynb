{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ET-NAS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BIsGjTfcbv-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5dc4f6-eff0-4090-94ea-4901ef0ad04b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/GitHub"
      ],
      "metadata": {
        "id": "ybZcbZlBclww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4cf8f07-7129-433c-de03-60dbb80fa5c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GitHub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repository = \"NAS_project\""
      ],
      "metadata": {
        "id": "tgj8z3YjcqsB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {repository}"
      ],
      "metadata": {
        "id": "hCjRhZdwcrs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9294988d-40aa-41e7-dae9-0315547a0d8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GitHub/NAS_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nats_bench"
      ],
      "metadata": {
        "id": "6pW1eAFrczUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yacs"
      ],
      "metadata": {
        "id": "EpSGj_ccc4KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install simplejson"
      ],
      "metadata": {
        "id": "zW5Pmym0c7TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xautodl"
      ],
      "metadata": {
        "id": "e4BRbwA8c-aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorchcv"
      ],
      "metadata": {
        "id": "gQHmOqI_iJId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env TORCH_HOME=/content/drive/MyDrive/NAS-PULITO/.torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEheGLe8dGRK",
        "outputId": "a69c1105-51ca-4c18-bb13-b500263e3ab6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: TORCH_HOME=/content/drive/MyDrive/NAS-PULITO/.torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import librerie\n",
        "\n",
        "# librerie giÃ  presenti nelle prime versioni\n",
        "import torch\n",
        "import argparse\n",
        "import datasets \n",
        "import nasspace\n",
        "import pandas as pd\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "import os\n",
        "from scipy import stats\n",
        "from nats_bench import create\n",
        "import xautodl  # import this lib -- \"https://github.com/D-X-Y/AutoDL-Projects\", you can use pip install xautodl\n",
        "from xautodl.models import get_cell_based_tiny_net\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import inf\n",
        "\n",
        "#librerie nuove\n",
        "from pycls.models.nas.nas import Cell\n",
        "import pandas as pd\n",
        "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "from pytorchcv.model_provider import _models as ptcv_models\n",
        "from pruners import *\n",
        "from pruners import predictive\n",
        "from tqdm import trange\n",
        "from statistics import mean\n",
        "from sklearn.preprocessing import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "from GenNAS.builder_task import *\n",
        "from GenNAS.builder_model import *\n",
        "from GenNAS.builder_evaluator import *\n",
        "from GenNAS.utils.config_generator import *\n"
      ],
      "metadata": {
        "id": "l6JAXjXEdHYS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SELECT DATASET\n",
        "#Dataset_name = \"Cifar-10\"\n",
        "#Dataset_name = \"Cifar-100\"\n",
        "Dataset_name = \"ImageNet\""
      ],
      "metadata": {
        "id": "p3VW6r7EYRxp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPU = '0'\n",
        "seed = 1\n",
        "batch_size = 128\n",
        "\n",
        "#CIFAR10\n",
        "if Dataset_name == \"Cifar-10\":\n",
        "  dataset = 'cifar10'\n",
        "  data_loc = '/content/drive/MyDrive/Github/NAS-PULITO/cifar-10-batches-py'\n",
        "\n",
        "\n",
        "#CIFAR100\n",
        "if Dataset_name == \"Cifar-100\":\n",
        "  dataset = 'cifar100'\n",
        "  data_loc = \"/content/drive/MyDrive/NAS-PULITO/cifar-100-python\"\n",
        "\n",
        "#IMAGENET\n",
        "if Dataset_name == \"ImageNet\":\n",
        "  dataset = 'ImageNet16-120'\n",
        "  data_loc = \"/content/drive/MyDrive/NAS/.torch/ImageNet16\"\n",
        "\n"
      ],
      "metadata": {
        "id": "0t7HP6w6eD2q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
        "\n",
        "# Reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "7bKx87xQel8n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "import torch\n",
        "\n",
        "\n",
        "def get_naswot(network, x):\n",
        "  network = network.to(device)\n",
        "\n",
        "  def boolRelu_forward_hook(module, inp, out):\n",
        "    if isinstance(out, tuple):\n",
        "      out = out[0]\n",
        "    out = out.view(out.size(0), -1)   \n",
        "    x = (out > 0).float()  \n",
        "    network.boolRelu = torch.cat((network.boolRelu, x), -1)\n",
        "    \n",
        "  network.boolRelu = torch.tensor([])\n",
        "  network.boolRelu = network.boolRelu.to(device)\n",
        "\n",
        "  for name, module in network.named_modules(): \n",
        "    if (isinstance(module, torch.nn.modules.activation.ReLU)):\n",
        "      module.register_forward_hook(boolRelu_forward_hook)\n",
        "              \n",
        "\n",
        "  network(x)\n",
        "  k = (network.boolRelu @ network.boolRelu.t()) + ((1. - network.boolRelu) @ (1. - network.boolRelu.t()))\n",
        "  logdet = torch.linalg.slogdet(k)[1].cpu().detach()\n",
        "  torch.cuda.empty_cache()\n",
        "  return logdet\n",
        "  #return (logdet, (end - start))"
      ],
      "metadata": {
        "id": "rZTei2yNfFZv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NNDegree(searchspace, uid):\n",
        "\n",
        "  strOp = searchspace.get_str(uid)\n",
        "  listOp = strOp.split('|')\n",
        "  id = [1,4,8]\n",
        "  nConv = strOp.count('conv')\n",
        "  skip1 = [3,7]\n",
        "  skip2 = [6]\n",
        "  nID = ''.join([i for j, i in enumerate(listOp) if j in id]).count('skip')\n",
        "  nS1 = ''.join([i for j, i in enumerate(listOp) if j in skip1]).count('skip')\n",
        "  nS2  = ''.join([i for j, i in enumerate(listOp) if j in skip2]).count('skip')\n",
        "  nNone = strOp.count('none')\n",
        "  #skip = searchspace.get_unique_str(uid).count('skip')\n",
        "  Sc = (nS1+2*nS2)\n",
        "  Wc = nConv\n",
        "  return int((Wc + Sc))"
      ],
      "metadata": {
        "id": "QpShe1zKff-2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import inf\n",
        "\n",
        "def get_uid_and_measure(uid, input, metric_name, population = None):\n",
        "  scaler = StandardScaler()\n",
        "  uid = int(uid)\n",
        "  network = searchspace.get_network(uid)\n",
        "  network.to(device)\n",
        "  if metric_name == \"Naswot\":\n",
        "    return uid, get_naswot(network, input).item()\n",
        "  elif metric_name == \"log_synflow\":\n",
        "    deg =  NNDegree(searchspace, uid)\n",
        "    return uid, predictive.get_log_syn(network, input), deg\n",
        "  elif metric_name == \"normalize\":\n",
        "    naswot = get_naswot(network, train_loader).item()\n",
        "    deg =  NNDegree(searchspace, uid)\n",
        "    p = population[:,[0,2,3]]\n",
        "    #print(\"p: \", p)\n",
        "    #print(\"np.array([uid, degree, naswot]): \", np.array([uid, naswot, deg]))\n",
        "    p = np.vstack((p, np.array([uid, naswot, deg])))\n",
        "    #print(p)\n",
        "    p[p == -inf] = 0\n",
        "    NWnor = scaler.fit_transform(p[:,1].reshape(-1,1))\n",
        "    degree = scaler.fit_transform(p[:,2].reshape(-1,1))\n",
        "    return (uid , NWnor[-1].item()+degree[-1].item(),  naswot, deg)\n",
        "\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "h7cSA1fNftMi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import inf\n",
        " #uid, sum, naswot, deg, acc\n",
        "\n",
        "def sum_syn_naswot_degree(list_measures, input, searchspace, task, model_builder, evaluator):\n",
        "  nas = []\n",
        "  slope = []\n",
        "  scaler = StandardScaler()\n",
        "  list_measures[list_measures == -inf] = 0\n",
        "  syn = list_measures[:,1].reshape(-1,1)\n",
        "  #deg = scaler.fit_transform(list_measures[:,2].reshape(-1,1))\n",
        "  syn_nor = scaler.fit_transform(list_measures[:,1].reshape(-1,1))\n",
        "  degree = list_measures[:,2].reshape(-1,1)\n",
        "  deg = scaler.fit_transform(list_measures[:,2].reshape(-1,1))\n",
        "  for uid in list_measures[:,0]:\n",
        "      network = searchspace.get_network(int(uid))\n",
        "      network.to(device)\n",
        "      nas.append([ get_naswot(network, input).item()])\n",
        "      #slope.append([get_regression_score(int(uid), task, model_builder,evaluator)])\n",
        "  #return (list_measures[:,0], NWnor, degree, syn)\n",
        "  naswot = np.array(nas).reshape(-1,1)\n",
        "  WNor = scaler.fit_transform(np.array(nas).reshape(-1,1))\n",
        "  #sl = scaler.fit_transform(np.array(slope).reshape(-1,1))\n",
        "  measures = np.hstack((list_measures[:,0].reshape(-1,1), syn_nor+WNor+deg, syn, naswot, degree)) #NWnor+degree+syn+\n",
        "  return measures"
      ],
      "metadata": {
        "id": "1Fe9Ab7Xb_pr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_uid_and_measures(uid_list, input, searchspace, metric_name):\n",
        "  naswot = []\n",
        "  log_Syn = []\n",
        "  norm = []\n",
        "\n",
        "  if metric_name == \"Naswot\":\n",
        "    for uid in uid_list:\n",
        "      network = searchspace.get_network(int(uid))\n",
        "      network.to(device)\n",
        "      naswot.append([uid, get_naswot(network, input).item()])\n",
        "    return np.array(naswot)\n",
        "  elif metric_name == \"log_synflow\":\n",
        "    for uid in uid_list:\n",
        "      deg =  NNDegree(searchspace, uid)\n",
        "      network = searchspace.get_network(int(uid))\n",
        "      log_Syn.append([uid, predictive.get_log_syn(network, input), deg])\n",
        "    return np.array(log_Syn)\n",
        "  elif metric_name == \"normalize\":\n",
        "    for uid in uid_list:\n",
        "      network = searchspace.get_network(int(uid))\n",
        "      network.to(device)\n",
        "      #net2 = searchspace.get_network(int(uid))\n",
        "      norm.append([uid, get_naswot(network, train_loader).item(), NNDegree(searchspace, uid)])\n",
        "    return sum_normalize(np.array(norm))\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "BKWeqA9vf-r1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_archs(searchspace,list_uid):\n",
        "  list_arch = []\n",
        "  for uid in list_uid:\n",
        "    list_arch.append(searchspace.get_unique_str(uid))\n",
        "  return list_arch"
      ],
      "metadata": {
        "id": "MA2PRbOigFF7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lossSlope(losslist):\n",
        "  trend = np.polyfit(range(len(losslist[1:10])),losslist[1:10],1)\n",
        "  return trend[0]\n",
        "  #trendpoly = np.poly1d(trend) \n",
        "  #return trendpoly(len(losslist)+10)"
      ],
      "metadata": {
        "id": "toRXYQR2gF2p"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LAS_score(losslist):\n",
        "  weight = np.logspace(0, 1, len(losslist[1:]), endpoint=True)\n",
        "  return np.log(np.dot(losslist[1:], weight))#/weight.sum()  #- np.sqrt(len(losslist))*abs(np.polyfit(range(len(losslist)),losslist,1)[0])"
      ],
      "metadata": {
        "id": "iU5jpKg_TSbe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LAS_score_trp(losslist):\n",
        "  return np.trapz(losslist, dx= 0.1)"
      ],
      "metadata": {
        "id": "UfTQPcv6Tekl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tse_ema(losslist):\n",
        "  mu = 0.70\n",
        "  m = np.linspace(1, 0, num=len(losslist[1:]))\n",
        "  for i, loss in enumerate(losslist[1:]):\n",
        "    if i <= 0:\n",
        "      ema = loss\n",
        "    else:\n",
        "      ema = ema * (1 - mu) + mu * loss \n",
        "      #ema = ema * (1 - m[i]) + m[i] * loss\n",
        "\n",
        "  return ema"
      ],
      "metadata": {
        "id": "TcsVL9PnThWh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LAS_score_g(losslist):\n",
        "  return -np.sum((np.gradient(losslist[1:])))"
      ],
      "metadata": {
        "id": "Ag7J0Lm9Tj-A"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_regression_score(uid, task, model_builder, evaluator):\n",
        "  arch = searchspace.get_str(uid)\n",
        "  losses = evaluator.evaluate(task, model_builder, arch)\n",
        "  return -lossSlope(list(losses))\n",
        "  #return -list(losses)[-1]\n",
        "  #return (LAS_score_trp(list(losses)))\n",
        "  #return (tse_ema(list(losses)))\n",
        "  #return (-LAS_score_g(list(losses)))\n",
        "  #return (-LAS_score(list(losses)))"
      ],
      "metadata": {
        "id": "eqD0BGNSgN6i"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def dominates(obj1, obj2, sign=[1, 1]):\n",
        "    \"\"\"Return true if each objective of *self* is not strictly worse than\n",
        "            the corresponding objective of *other* and at least one objective is\n",
        "            strictly better.\n",
        "        **no need to care about the equal cases\n",
        "        (Cuz equal cases mean they are non-dominators)\n",
        "    :param obj1: a list of multiple objective values\n",
        "    :type obj1: numpy.ndarray\n",
        "    :param obj2: a list of multiple objective values\n",
        "    :type obj2: numpy.ndarray\n",
        "    :param sign: target types. positive means maximize and otherwise minimize.\n",
        "    :type sign: list\n",
        "    \"\"\"\n",
        "    indicator = False\n",
        "    for a, b, sign in zip(obj1, obj2, sign):\n",
        "        if a * sign > b * sign:\n",
        "            indicator = True\n",
        "        # if one of the objectives is dominated, then return False\n",
        "        elif a * sign < b * sign:\n",
        "            return False\n",
        "    return indicator\n",
        "\n",
        "\n",
        "def sortNondominated(fitness, k=None, first_front_only=False):\n",
        "    \"\"\"Sort the first *k* *individuals* into different nondomination levels\n",
        "        using the \"Fast Nondominated Sorting Approach\" proposed by Deb et al.,\n",
        "        see [Deb2002]_. This algorithm has a time complexity of :math:`O(MN^2)`,\n",
        "        where :math:`M` is the number of objectives and :math:`N` the number of\n",
        "        individuals.\n",
        "        :param individuals: A list of individuals to select from.\n",
        "        :param k: The number of individuals to select.\n",
        "        :param first_front_only: If :obj:`True` sort only the first front and\n",
        "                                    exit.\n",
        "        :param sign: indicate the objectives are maximized or minimized\n",
        "        :returns: A list of Pareto fronts (lists), the first list includes\n",
        "                    nondominated individuals.\n",
        "        .. [Deb2002] Deb, Pratab, Agarwal, and Meyarivan, \"A fast elitist\n",
        "            non-dominated sorting genetic algorithm for multi-objective\n",
        "            optimization: NSGA-II\", 2002.\n",
        "    \"\"\"\n",
        "    fitness = np.ndarray.tolist(fitness)\n",
        "    if k is None:\n",
        "        k = len(fitness)\n",
        "\n",
        "    # Use objectives as keys to make python dictionary\n",
        "    map_fit_ind = defaultdict(list)\n",
        "    for i, f_value in enumerate(fitness):  # fitness = [(1, 2), (2, 2), (3, 1), (1, 4), (1, 1)...]\n",
        "        map_fit_ind[tuple(f_value)].append(i)\n",
        "    fits = list(map_fit_ind.keys())  # fitness values\n",
        "\n",
        "    current_front = []\n",
        "    next_front = []\n",
        "    dominating_fits = defaultdict(int)  # n (The number of people dominate you)\n",
        "    dominated_fits = defaultdict(list)  # Sp (The people you dominate)\n",
        "\n",
        "    # Rank first Pareto front\n",
        "    # *fits* is a iterable list of chromosomes. Each has multiple objectives.\n",
        "    for i, fit_i in enumerate(fits):\n",
        "        for fit_j in fits[i + 1:]:\n",
        "            # Eventhougn equals or empty list, n & Sp won't be affected\n",
        "            if dominates(fit_i, fit_j):\n",
        "                dominating_fits[fit_j] += 1  \n",
        "                dominated_fits[fit_i].append(fit_j)  \n",
        "            elif dominates(fit_j, fit_i):  \n",
        "                dominating_fits[fit_i] += 1\n",
        "                dominated_fits[fit_j].append(fit_i)\n",
        "        if dominating_fits[fit_i] == 0: \n",
        "            current_front.append(fit_i)\n",
        "\n",
        "    fronts = [[]]  # The first front\n",
        "    for fit in current_front:\n",
        "        fronts[-1].extend(map_fit_ind[fit])\n",
        "    pareto_sorted = len(fronts[-1])\n",
        "\n",
        "    # Rank the next front until all individuals are sorted or\n",
        "    # the given number of individual are sorted.\n",
        "    # If Sn=0 then the set of objectives belongs to the next front\n",
        "    if not first_front_only:  # first front only\n",
        "        N = min(len(fitness), k)\n",
        "        while pareto_sorted < N:\n",
        "            fronts.append([])\n",
        "            for fit_p in current_front:\n",
        "                # Iterate Sn in current fronts\n",
        "                for fit_d in dominated_fits[fit_p]: \n",
        "                    dominating_fits[fit_d] -= 1  # Next front -> Sn - 1\n",
        "                    if dominating_fits[fit_d] == 0:  # Sn=0 -> next front\n",
        "                        next_front.append(fit_d)\n",
        "                         # Count and append chromosomes with same objectives\n",
        "                        pareto_sorted += len(map_fit_ind[fit_d]) \n",
        "                        fronts[-1].extend(map_fit_ind[fit_d])\n",
        "            current_front = next_front\n",
        "            next_front = []\n",
        "\n",
        "    return np.array(fronts)"
      ],
      "metadata": {
        "id": "Q3er95CXco8o"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CrowdingDist(fitness=None):\n",
        "    \"\"\"\n",
        "    :param fitness: A list of fitness values\n",
        "    :return: A list of crowding distances of chrmosomes\n",
        "    \n",
        "    The crowding-distance computation requires sorting the population according to each objective function value \n",
        "    in ascending order of magnitude. Thereafter, for each objective function, the boundary solutions (solutions with smallest and largest function values) \n",
        "    are assigned an infinite distance value. All other intermediate solutions are assigned a distance value equal to \n",
        "    the absolute normalized difference in the function values of two adjacent solutions.\n",
        "    \"\"\"\n",
        "\n",
        "    # initialize list: [0.0, 0.0, 0.0, ...]\n",
        "    distances = [0.0] * len(fitness)\n",
        "    crowd = [(f_value, i) for i, f_value in enumerate(fitness)]  # create keys for fitness values\n",
        "\n",
        "    n_obj = len(fitness[0])\n",
        "\n",
        "    for i in range(n_obj):  # calculate for each objective\n",
        "        crowd.sort(key=lambda element: element[0][i])\n",
        "        # After sorting,  boundary solutions are assigned Inf \n",
        "        # crowd: [([obj_1, obj_2, ...], i_0), ([obj_1, obj_2, ...], i_1), ...]\n",
        "        distances[crowd[0][1]] = float(\"Inf\")\n",
        "        distances[crowd[-1][1]] = float(\"inf\")\n",
        "        if crowd[-1][0][i] == crowd[0][0][i]:  # If objective values are same, skip this loop\n",
        "            continue\n",
        "        # normalization (max - min) as Denominator\n",
        "        norm = float(crowd[-1][0][i] - crowd[0][0][i])\n",
        "        # crowd: [([obj_1, obj_2, ...], i_0), ([obj_1, obj_2, ...], i_1), ...]\n",
        "        # calculate each individual's Crowding Distance of i th objective\n",
        "        # technique: shift the list and zip\n",
        "        for prev, cur, next in zip(crowd[:-2], crowd[1:-1], crowd[2:]):\n",
        "            distances[cur[1]] += (next[0][i] - prev[0][i]) / norm  # sum up the distance of ith individual along each of the objectives\n",
        "\n",
        "    return distances"
      ],
      "metadata": {
        "id": "H7CU4yjQUGah"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def closest_node(node, nodes):\n",
        "    nodes = np.asarray(nodes)\n",
        "    dist_2 = np.sum((nodes - node)**2, axis=1)\n",
        "    return np.argmin(dist_2)"
      ],
      "metadata": {
        "id": "O9j7w2I6UP5U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class args:\n",
        "  pass\n",
        "\n",
        "args.total_iters = 10 #100\n",
        "args.eval_interval = 1 #10\n",
        "args.init_w_type = 'none'\n",
        "args.init_b_type = 'none'\n",
        "args.learning_rate = 1e-1\n",
        "args.weight_decay = 4e-5\n",
        "args.momentum = 0.9 \n",
        "args.eval_weights = [0.25,0.5,1.]\n",
        "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "args.train_weights = [0.25,0.5,1.]\n",
        "args.config = \"CONF_NB101\"\n",
        "args.workers = 2\n",
        "args.pad = 'store_true'\n",
        "args.input_size = 32 #cifar 32?\n",
        "args.output_size = 8 #cifar 8?\n",
        "args.last_channels = 64\n",
        "args.batch_size = 16 #16\n",
        "#CIFAR10\n",
        "if Dataset_name == \"Cifar-10\":\n",
        "  args.data_loc = '/content/drive/MyDrive/Github/NAS-PULITO/cifar-10-batches-py'\n",
        "  args.dataset = 'cifar10'\n",
        "  args.num_labels = 10\n",
        "\n",
        "#CIFAR100\n",
        "if Dataset_name == \"Cifar-100\":\n",
        "  args.dataset = 'cifar100'\n",
        "  args.data_loc = \"/content/drive/MyDrive/NAS-PULITO/cifar-100-python\"\n",
        "  args.num_labels = 100\n",
        "\n",
        "#IMAGENET\n",
        "if Dataset_name == \"ImageNet\":\n",
        "  args.dataset = 'ImageNet16-120'\n",
        "  args.data_loc = \"/content/drive/MyDrive/NAS/.torch/ImageNet16\"\n",
        "  args.num_labels = 120\n",
        "\n",
        "args.init_channels = 16\n",
        "args.search_space = 'nasbench201'"
      ],
      "metadata": {
        "id": "9-3gVvRpgQ4K"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#CIFAR 10\n",
        "if Dataset_name == \"Cifar-10\":\n",
        "  df_iso = pd.read_csv('/content/drive/MyDrive/GitHub/NAS_project/naswot_cifar10_batch128_seed1_isomorf.csv')\n",
        "  df_non_iso = pd.read_csv('/content/drive/MyDrive/GitHub/NAS_project/naswot_cifar10_batch128_completo.csv')\n",
        "  df = df_non_iso.append(df_iso)\n",
        "\n",
        "#CIFAR100\n",
        "if Dataset_name == \"Cifar-100\":\n",
        "  df_iso = pd.read_csv('/content/drive/MyDrive/GitHub/NAS_project/naswot_cifar100_batch128_seed1_isomorf.csv')\n",
        "  df_non_iso = pd.read_csv('/content/drive/MyDrive/GitHub/NAS_project/naswot_cifar100_batch128_completo.csv')\n",
        "  df = df_non_iso.append(df_iso)\n",
        "\n",
        "#IMAGENET\n",
        "if Dataset_name == \"ImageNet\":\n",
        "  df = pd.read_csv('/content/drive/MyDrive/GitHub/NAS_project/naswot_ImageNet16-120_batch128_seed1_15625Arch.csv')\n",
        "\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XKtI4q4LjviR",
        "outputId": "27be275d-52fc-453f-8000-0b191a2f49f4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Unnamed: 0  arch_id                                           uniqArch  \\\n",
              "0               0        0  (0)@avg_pool_3x3+(0)@avg_pool_3x3+(0)@nor_conv...   \n",
              "1               1        1  ((0)@nor_conv_3x3)@avg_pool_3x3+(0)@nor_conv_3...   \n",
              "2               2        2  (((0)@avg_pool_3x3)@nor_conv_3x3+(0)@nor_conv_...   \n",
              "3               3        3                                            #+#+#+0   \n",
              "4               4        4              ((0)@nor_conv_1x1+0)@nor_conv_1x1+0+0   \n",
              "...           ...      ...                                                ...   \n",
              "15620        9155    15620                                              #+#+0   \n",
              "15621        9156    15621                #+((0)@avg_pool_3x3)@nor_conv_1x1+0   \n",
              "15622        9157    15622  #+((0)@nor_conv_3x3+(0)@nor_conv_3x3)@nor_conv...   \n",
              "15623        9158    15623  #+(#+(0)@avg_pool_3x3)@avg_pool_3x3+(0)@avg_po...   \n",
              "15624        6465    15624  #+(#+((0)@nor_conv_1x1)@nor_conv_1x1)@nor_conv...   \n",
              "\n",
              "             score      time        acc  \n",
              "0      1281.548950  0.055238  28.211111  \n",
              "1      1380.631348  0.058419  44.488889  \n",
              "2      1263.264526  0.042976  27.633333  \n",
              "3      1047.412598  0.028810  29.433333  \n",
              "4      1309.597046  0.041116  32.144444  \n",
              "...            ...       ...        ...  \n",
              "15620  1054.735596  0.030721  29.822222  \n",
              "15621  1227.618652  0.034945  31.800000  \n",
              "15622  1390.784668  0.049597  41.855555  \n",
              "15623   962.202087  0.030363  14.411111  \n",
              "15624  1434.844238  0.054381  21.388889  \n",
              "\n",
              "[15625 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d240a9fa-0709-4ffa-8b2d-32fbf105ef3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>arch_id</th>\n",
              "      <th>uniqArch</th>\n",
              "      <th>score</th>\n",
              "      <th>time</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(0)@avg_pool_3x3+(0)@avg_pool_3x3+(0)@nor_conv...</td>\n",
              "      <td>1281.548950</td>\n",
              "      <td>0.055238</td>\n",
              "      <td>28.211111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>((0)@nor_conv_3x3)@avg_pool_3x3+(0)@nor_conv_3...</td>\n",
              "      <td>1380.631348</td>\n",
              "      <td>0.058419</td>\n",
              "      <td>44.488889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>(((0)@avg_pool_3x3)@nor_conv_3x3+(0)@nor_conv_...</td>\n",
              "      <td>1263.264526</td>\n",
              "      <td>0.042976</td>\n",
              "      <td>27.633333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>#+#+#+0</td>\n",
              "      <td>1047.412598</td>\n",
              "      <td>0.028810</td>\n",
              "      <td>29.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>((0)@nor_conv_1x1+0)@nor_conv_1x1+0+0</td>\n",
              "      <td>1309.597046</td>\n",
              "      <td>0.041116</td>\n",
              "      <td>32.144444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15620</th>\n",
              "      <td>9155</td>\n",
              "      <td>15620</td>\n",
              "      <td>#+#+0</td>\n",
              "      <td>1054.735596</td>\n",
              "      <td>0.030721</td>\n",
              "      <td>29.822222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15621</th>\n",
              "      <td>9156</td>\n",
              "      <td>15621</td>\n",
              "      <td>#+((0)@avg_pool_3x3)@nor_conv_1x1+0</td>\n",
              "      <td>1227.618652</td>\n",
              "      <td>0.034945</td>\n",
              "      <td>31.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15622</th>\n",
              "      <td>9157</td>\n",
              "      <td>15622</td>\n",
              "      <td>#+((0)@nor_conv_3x3+(0)@nor_conv_3x3)@nor_conv...</td>\n",
              "      <td>1390.784668</td>\n",
              "      <td>0.049597</td>\n",
              "      <td>41.855555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15623</th>\n",
              "      <td>9158</td>\n",
              "      <td>15623</td>\n",
              "      <td>#+(#+(0)@avg_pool_3x3)@avg_pool_3x3+(0)@avg_po...</td>\n",
              "      <td>962.202087</td>\n",
              "      <td>0.030363</td>\n",
              "      <td>14.411111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15624</th>\n",
              "      <td>6465</td>\n",
              "      <td>15624</td>\n",
              "      <td>#+(#+((0)@nor_conv_1x1)@nor_conv_1x1)@nor_conv...</td>\n",
              "      <td>1434.844238</td>\n",
              "      <td>0.054381</td>\n",
              "      <td>21.388889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15625 rows Ã 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d240a9fa-0709-4ffa-8b2d-32fbf105ef3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d240a9fa-0709-4ffa-8b2d-32fbf105ef3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d240a9fa-0709-4ffa-8b2d-32fbf105ef3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.sort_values(by=[\"acc\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PfKJQbWR8nC6",
        "outputId": "e13fba47-97f2-40a1-c577-2d3314320418"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Unnamed: 0  arch_id                                           uniqArch  \\\n",
              "13286        7642    13286                             #+#+(#+#)@nor_conv_3x3   \n",
              "12746        7297    12746                                              #+#+#   \n",
              "13078        7506    13078                                              #+#+#   \n",
              "8354         4448     8354                                              #+#+#   \n",
              "632           156      632                             #+#+(#+#)@avg_pool_3x3   \n",
              "...           ...      ...                                                ...   \n",
              "8449         3936     8449  (#+((0)@nor_conv_3x3)@nor_conv_3x3)@nor_conv_1...   \n",
              "11777        5099    11777  #+(((0)@nor_conv_3x3)@nor_conv_3x3+(0)@nor_con...   \n",
              "3731         2003     3731  (((0)@nor_conv_3x3)@nor_conv_3x3+(0)@nor_conv_...   \n",
              "3888         2082     3888  (((0)@nor_conv_1x1)@nor_conv_3x3+(0)@nor_conv_...   \n",
              "10676        4724    10676  (((0)@nor_conv_3x3)@nor_conv_1x1+(0)@nor_conv_...   \n",
              "\n",
              "             score      time        acc  \n",
              "13286         -inf  0.036226   0.833333  \n",
              "12746  1056.087158  0.050810   0.833333  \n",
              "13078  1056.087158  0.050810   0.833333  \n",
              "8354   1056.087158  0.050810   0.833333  \n",
              "632           -inf  0.038140   0.833333  \n",
              "...            ...       ...        ...  \n",
              "8449   1423.089355  0.063976  46.500000  \n",
              "11777  1453.754639  0.063623  46.516667  \n",
              "3731   1447.406860  0.061208  46.555555  \n",
              "3888   1450.777466  0.066033  46.683333  \n",
              "10676  1447.762207  0.060038  46.733333  \n",
              "\n",
              "[15625 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3ace01e-6da2-4174-86d4-5d8168313290\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>arch_id</th>\n",
              "      <th>uniqArch</th>\n",
              "      <th>score</th>\n",
              "      <th>time</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13286</th>\n",
              "      <td>7642</td>\n",
              "      <td>13286</td>\n",
              "      <td>#+#+(#+#)@nor_conv_3x3</td>\n",
              "      <td>-inf</td>\n",
              "      <td>0.036226</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12746</th>\n",
              "      <td>7297</td>\n",
              "      <td>12746</td>\n",
              "      <td>#+#+#</td>\n",
              "      <td>1056.087158</td>\n",
              "      <td>0.050810</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13078</th>\n",
              "      <td>7506</td>\n",
              "      <td>13078</td>\n",
              "      <td>#+#+#</td>\n",
              "      <td>1056.087158</td>\n",
              "      <td>0.050810</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8354</th>\n",
              "      <td>4448</td>\n",
              "      <td>8354</td>\n",
              "      <td>#+#+#</td>\n",
              "      <td>1056.087158</td>\n",
              "      <td>0.050810</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>156</td>\n",
              "      <td>632</td>\n",
              "      <td>#+#+(#+#)@avg_pool_3x3</td>\n",
              "      <td>-inf</td>\n",
              "      <td>0.038140</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8449</th>\n",
              "      <td>3936</td>\n",
              "      <td>8449</td>\n",
              "      <td>(#+((0)@nor_conv_3x3)@nor_conv_3x3)@nor_conv_1...</td>\n",
              "      <td>1423.089355</td>\n",
              "      <td>0.063976</td>\n",
              "      <td>46.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11777</th>\n",
              "      <td>5099</td>\n",
              "      <td>11777</td>\n",
              "      <td>#+(((0)@nor_conv_3x3)@nor_conv_3x3+(0)@nor_con...</td>\n",
              "      <td>1453.754639</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>46.516667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3731</th>\n",
              "      <td>2003</td>\n",
              "      <td>3731</td>\n",
              "      <td>(((0)@nor_conv_3x3)@nor_conv_3x3+(0)@nor_conv_...</td>\n",
              "      <td>1447.406860</td>\n",
              "      <td>0.061208</td>\n",
              "      <td>46.555555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3888</th>\n",
              "      <td>2082</td>\n",
              "      <td>3888</td>\n",
              "      <td>(((0)@nor_conv_1x1)@nor_conv_3x3+(0)@nor_conv_...</td>\n",
              "      <td>1450.777466</td>\n",
              "      <td>0.066033</td>\n",
              "      <td>46.683333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10676</th>\n",
              "      <td>4724</td>\n",
              "      <td>10676</td>\n",
              "      <td>(((0)@nor_conv_3x3)@nor_conv_1x1+(0)@nor_conv_...</td>\n",
              "      <td>1447.762207</td>\n",
              "      <td>0.060038</td>\n",
              "      <td>46.733333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15625 rows Ã 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3ace01e-6da2-4174-86d4-5d8168313290')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3ace01e-6da2-4174-86d4-5d8168313290 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3ace01e-6da2-4174-86d4-5d8168313290');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.config = eval(args.config)"
      ],
      "metadata": {
        "id": "_f3Sg6RDg3KP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = Evaluator(args)\n",
        "task = CVTask(args)\n",
        "model_builder = ModelBuilder(args)"
      ],
      "metadata": {
        "id": "D6mMlZzsg37v"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_config = pd.read_csv(\"conf.csv\")"
      ],
      "metadata": {
        "id": "6Ad9Tir0x4ht"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "searchspace = nasspace.get_search_space(dataset, df_config.conf)\n",
        "train_loader = datasets.get_data(dataset, data_loc, batch_size)\n",
        "\n",
        "data_iterator = iter(train_loader)\n",
        "input, target = next(data_iterator)\n",
        "input, target = input.to(device), target.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3gbWoWVx8tk",
        "outputId": "99984de2-0b35-4dc3-ebc9-becb07649f8e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-08-28 19:17:02] Try to use the default NATS-Bench (topology) path from fast_mode=True and path=None.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caloclo ET-NAS"
      ],
      "metadata": {
        "id": "zh5OWISoJFRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import default_rng\n",
        "\n",
        "Number_experiments = 30\n",
        "filename = f'ET-NAS_on_{dataset}_in_{Number_experiments}_experimets.csv'\n",
        "arch_dict = []\n",
        "\n",
        "arch_info = ['arch_id' , 'time', 'acc', 'test_acc']\n",
        "history = []\n",
        "from numpy.random import default_rng\n",
        "population_size=20 \n",
        "n_sample=5\n",
        "cycles= 60\n",
        "\n",
        "for j in range(0,Number_experiments):\n",
        "  print(j)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  new_gen = []\n",
        "  history = []\n",
        "\n",
        "\n",
        "  start = timer()\n",
        "\n",
        "  uid_population =  random.sample(range(len(searchspace)),population_size)\n",
        "\n",
        "  population =  get_uid_and_measures(uid_population, input, searchspace, \"log_synflow\") \n",
        "\n",
        "  history = get_archs(searchspace, uid_population)\n",
        "\n",
        "          \n",
        "  while len(history) <= cycles:\n",
        "\n",
        "      uid_sample = random.sample(range(len(population)),n_sample)\n",
        "\n",
        "      sample = population[uid_sample]\n",
        "\n",
        "      parent = max(sample[sample[:,2] == max(sample[:,2])], key=lambda i: i[1]) \n",
        "\n",
        "      child_idx = searchspace.mutate_arch(int(parent[0])) \n",
        "\n",
        "      unique_str_child = searchspace.get_unique_str(child_idx)\n",
        "\n",
        "      degree_child = NNDegree(searchspace, child_idx)\n",
        "\n",
        "      degree_parent = parent[-1]\n",
        "\n",
        "      if unique_str_child not in history and degree_child >= degree_parent:\n",
        "\n",
        "\n",
        "        uid_and_measure = np.array(get_uid_and_measure(child_idx, input, \"log_synflow\", population))\n",
        "\n",
        "        new_gen.append([int(uid_and_measure[0]), uid_and_measure[1], uid_and_measure[2] ])\n",
        "\n",
        "        population = np.delete(population, 0, axis=0)\n",
        "\n",
        "        population = np.vstack((population, uid_and_measure))\n",
        "\n",
        "        history.append(unique_str_child)\n",
        "\n",
        "\n",
        "     \n",
        "          \n",
        "          \n",
        "  \n",
        "\n",
        "  gen = np.array(new_gen)\n",
        "\n",
        "  gen = gen[gen[:,2] == max(gen[:,2])] #consider the architectures with higher NNdegree\n",
        "\n",
        "  measure= sum_syn_naswot_degree(gen, input, searchspace,task,model_builder,evaluator) \n",
        "\n",
        "  syn_naswot = measure[:,[2,3]]\n",
        "\n",
        "  pareto_index = sortNondominated(syn_naswot, first_front_only=True)\n",
        "  syn_naswot_pareto = syn_naswot[pareto_index[0]]\n",
        "  arch_pareto = measure[pareto_index[0]][:,0]\n",
        "\n",
        "\n",
        "  regression = []\n",
        "\n",
        "\n",
        "  if len(arch_pareto) > 1:\n",
        "    for uid in arch_pareto:\n",
        "      regression.append(get_regression_score(uid, task, model_builder,evaluator))\n",
        "    \n",
        "    syn_naswot_regression = np.hstack((syn_naswot_pareto, np.array(regression).reshape(-1,1)))\n",
        "    measures_normalized = (syn_naswot_regression) / (syn_naswot_regression.max(axis = 0))\n",
        "    best_arch_index = closest_node(np.array([1,1,1]), measures_normalized)\n",
        "    best_arch = arch_pareto[best_arch_index]\n",
        "    total_time_cost = (timer()-start)\n",
        "\n",
        "  else:\n",
        "    best_arch = arch_pareto[0]\n",
        "    total_time_cost = (timer()-start)\n",
        "\n",
        "\n",
        "  arch_dict.append({'arch_id' : int(best_arch), 'time': total_time_cost, 'acc' : df.set_index('arch_id').loc[int(best_arch), 'acc'], 'test_acc': searchspace.get_final_accuracy(int(best_arch)) })\n",
        "\n",
        "  with open(filename, 'w') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames = arch_info)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(arch_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AkYyB79BimiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OurRea_on_ImageNet16_120 = pd.read_csv(\"/content/drive/MyDrive/GitHub/NAS_project/ET-NAS_on_ImageNet16-120_in_30_experimets.csv\")\n",
        "print(OurRea_on_ImageNet16_120.mean())\n",
        "print(OurRea_on_ImageNet16_120.std())"
      ],
      "metadata": {
        "id": "2Z2U1czQWvXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aeb8b5b-3e8e-4001-f407-0790eb0a565b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arch_id     8368.133333\n",
            "time          26.992938\n",
            "acc           46.052963\n",
            "test_acc      46.317778\n",
            "dtype: float64\n",
            "arch_id     3934.282380\n",
            "time           4.191018\n",
            "acc            0.458222\n",
            "test_acc       0.214553\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}